# test_flow.py

import json
import logging

from crewai import Crew
from crewai.memory.external.external_memory import ExternalMemory

# ì´ë²¤íŠ¸ ë²„ìŠ¤/ì´ë²¤íŠ¸ íƒ€ì… ì„í¬íŠ¸
from crewai.utilities.events import CrewAIEventsBus
from crewai.utilities.events import LLMCallStartedEvent, LLMCallCompletedEvent
from crewai.utilities.events.task_events import TaskStartedEvent, TaskCompletedEvent
from crewai.utilities.events.agent_events import AgentExecutionStartedEvent, AgentExecutionCompletedEvent
from crewai.utilities.events import ToolUsageStartedEvent, ToolUsageFinishedEvent

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) ë¡œê·¸ ë ˆë²¨ ì„¤ì •
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
logging.basicConfig(level=logging.INFO)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡ (í”„ë¡¬í”„íŠ¸ & ì§„í–‰ ìƒí™© ëª¨ë‘)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
bus = CrewAIEventsBus()

# Task/Agent/Tool/LLM ì‹œì‘Â·ì¢…ë£Œ ì´ë²¤íŠ¸ ëª¨ë‘ ì¡ì•„ì„œ ê°„ë‹¨íˆ ìƒíƒœ ë¡œê·¸
for evt in [
    TaskStartedEvent, TaskCompletedEvent,
    AgentExecutionStartedEvent, AgentExecutionCompletedEvent,
    ToolUsageStartedEvent, ToolUsageFinishedEvent,
    LLMCallStartedEvent, LLMCallCompletedEvent
]:
    @bus.on(evt)
    def _generic_handler(source, event, evt=evt):
        et = event.type
        if et == "task_started":
            print(f"ğŸ“ íƒœìŠ¤í¬ ì‹œì‘: {event.task.id}")
        elif et == "task_completed":
            print("âœ… íƒœìŠ¤í¬ ì™„ë£Œ")
        elif et == "agent_execution_started":
            print(f"ğŸ¤– ì—ì´ì „íŠ¸ ì‹œì‘: {event.agent.role}")
        elif et == "agent_execution_completed":
            print("âœ… ì—ì´ì „íŠ¸ ì¢…ë£Œ")
        elif et == "tool_usage_started":
            print(f"ğŸ”§ ë„êµ¬ ì‹œì‘: {getattr(event, 'tool_name', '')}")
        elif et == "tool_usage_finished":
            print(f"âœ… ë„êµ¬ ì¢…ë£Œ: {getattr(event, 'tool_name', '')}")
        elif et == "llm_call_started":
            # 1) ì „ì²´ ë©”ì‹œì§€ êµ¬ì¡°ë¥¼ ì˜ˆì˜ê²Œ ì°ì–´ë³´ê¸°
            print("\nğŸ” [LLM â†’ Full messages payload]")
            print(json.dumps(event.messages, ensure_ascii=False, indent=2))

            # 2) role/content ë³„ë¡œë„ í•œ ì¤„ì”© ì­‰ ì°ì–´ë³´ê¸°
            for msg in event.messages:
                role = msg.get("role")
                content = msg.get("content")
                print(f"\n--- {role} message ---\n{content}\n")

            print("ğŸ”" + "â€•" * 60)
        elif et == "llm_call_completed":
            print("âœ… LLM í˜¸ì¶œ ì™„ë£Œ")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) run_flow ì •ì˜
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def run_flow(proc_inst_id: str, todos: list[str], memory=None):
    # 3-1) ë©”ëª¨ë¦¬ ì„¤ì •
    if memory is None:
        memory = ExternalMemory(
            embedder_config={
                "provider": "mem0",
                "config": {"user_id": proc_inst_id}
            }
        )

    # 3-2) ê° ìŠ¤í…ë³„ config
    requirement_config = {
        "agents": [{
            "name": "requirement_agent",
            "role": "assistant",
            "goal": "ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ ì´í•´í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.",
            "backstory": "ë‹¹ì‹ ì€ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            "type": "llm",
            "model": "gpt-4"
        }],
        "tasks": [{
            "name": "analyze_requirements",
            "agent": "assistant",
            # instruction ì— memory í”Œë ˆì´ìŠ¤í™€ë” í¬í•¨
            "instruction": (
                "ì´ì „ ë©”ëª¨ë¦¬ ë‚´ìš©:\n{memory}\n\n"
                "ì‘ì—…: {task}\n"
                "ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, ì£¼ì–´ì§„ ìš”êµ¬ì‚¬í•­ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìš”ì•½í•´ ì£¼ì„¸ìš”."
            ),
            "description": "ì£¼ì–´ì§„ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.",
            "expected_output": "text"
        }]
    }

    proposal_config = {
        "agents": [{
            "name": "proposal_agent",
            "role": "assistant",
            "goal": "ë¶„ì„ëœ ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ìœ¼ë¡œ ì œì•ˆì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
            "backstory": "ë‹¹ì‹ ì€ ì œì•ˆì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            "type": "llm",
            "model": "gpt-4"
        }],
        "tasks": [{
            "name": "draft_proposal",
            "agent": "assistant",
            "instruction": (
                "ì´ì „ ë¶„ì„ ê²°ê³¼:\n{memory}\n\n"
                "ì‘ì—…: {task}\n"
                "ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì œì•ˆì„œ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”."
            ),
            "description": "ì œì•ˆì„œ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤.",
            "expected_output": "text"
        }]
    }

    review_config = {
        "agents": [{
            "name": "review_agent",
            "role": "assistant",
            "goal": "ì‘ì„±ëœ ì œì•ˆì„œë¥¼ ê²€í† í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.",
            "backstory": "ë‹¹ì‹ ì€ ì œì•ˆì„œ ë¦¬ë·° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            "type": "llm",
            "model": "gpt-4"
        }],
        "tasks": [{
            "name": "review_proposal",
            "agent": "assistant",
            "instruction": (
                "ì´ì „ ì œì•ˆì„œ ì´ˆì•ˆ:\n{memory}\n\n"
                "ì‘ì—…: {task}\n"
                "ìœ„ ì´ˆì•ˆì„ ê²€í† í•˜ê³  ê°œì„ ì‚¬í•­ì„ ì œì•ˆí•˜ì„¸ìš”."
            ),
            "description": "ì œì•ˆì„œë¥¼ ê²€í† í•˜ê³  ê°œì„ ì‚¬í•­ì„ ì œì•ˆí•©ë‹ˆë‹¤.",
            "expected_output": "text"
        }]
    }

    # 3-3) Crew ìƒì„±
    crews = [
        Crew(name="RequirementCrew", memory=True, external_memory=memory, config=requirement_config),
        Crew(name="ProposalCrew",    memory=True, external_memory=memory, config=proposal_config),
        Crew(name="ReviewCrew",      memory=True, external_memory=memory, config=review_config),
    ]

    # 3-4) ìˆœì°¨ ì‹¤í–‰
    for idx, (crew, todo) in enumerate(zip(crews, todos), start=1):
        print(f"\n--- Flow {proc_inst_id} | Step {idx}: {crew.name} ---")
        print(f"í•  ì¼: {todo}")
        result = crew.kickoff(inputs={"task": todo})
        print(f"[{crew.name}] ê²°ê³¼:\n{result}\n")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4) main
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if __name__ == "__main__":
    todos = [
        "ìš”êµ¬ì‚¬í•­ ì „ë‹¬",
        "ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ì œì•ˆì„œ ì‘ì„±",
        "ì œì•ˆì„œ í”¼ë“œë°± ë° ê²€í† "
    ]
    proc_inst_id = "proc_002"

    print("=== ê¸°ë³¸ mem0 ë²¡í„° DB í…ŒìŠ¤íŠ¸ (ì´ë²¤íŠ¸ ë¡œê¹… í¬í•¨) ===")
    run_flow(proc_inst_id, todos)

    print("\n=== ì™¸ë¶€ Pinecone ë²¡í„° DB í…ŒìŠ¤íŠ¸ ===")
    pinecone_memory = ExternalMemory(
        embedder_config={
            "provider": "pinecone",
            "config": {
                "api_key": "<YOUR_API_KEY>",
                "environment": "<YOUR_ENV>",
                "index_name": proc_inst_id
            }
        }
    )
    run_flow(f"{proc_inst_id}_pinecone", todos, memory=pinecone_memory)
