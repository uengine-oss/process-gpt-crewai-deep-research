import os
import json
import traceback
from typing import Any
from contextvars import ContextVar
from dotenv import load_dotenv
import openai
import logging

# ============================================================================
# ì´ˆê¸°í™” ë° ì„¤ì •
# ============================================================================

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° OpenAI ì„¤ì •
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

logger = logging.getLogger(__name__)

# ContextVar ê¸°ë°˜ crew ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
crew_type_var: ContextVar[str] = ContextVar("crew_type", default="unknown")
todo_id_var: ContextVar[str] = ContextVar("todo_id", default=None)
proc_id_var: ContextVar[str] = ContextVar("proc_inst_id", default=None)
form_id_var: ContextVar[str] = ContextVar("form_id", default=None)

def _handle_error(operation: str, error: Exception) -> None:
    """í†µí•© ì—ëŸ¬ ì²˜ë¦¬"""
    error_msg = f"âŒ [{operation}] ì˜¤ë¥˜ ë°œìƒ: {str(error)}"
    print(error_msg)
    print(f"ìƒì„¸ ì •ë³´: {traceback.format_exc()}")
    raise Exception(f"{operation} ì‹¤íŒ¨: {error}")

# ============================================================================
# ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
# ============================================================================

def set_crew_context(crew_type: str, todo_id: str = None, proc_inst_id: str = None, form_id: str = None):
    """ContextVarì— crew ì •ë³´ ì„¤ì • ë° í† í° ë°˜í™˜"""
    try:
        token_ct = crew_type_var.set(crew_type)
        token_td = todo_id_var.set(todo_id)
        token_pid = proc_id_var.set(proc_inst_id)
        token_fid = form_id_var.set(form_id)
        return token_ct, token_td, token_pid, token_fid
    except Exception as e:
        _handle_error("ì»¨í…ìŠ¤íŠ¸ì„¤ì •", e)

def reset_crew_context(token_ct, token_td, token_pid, token_fid):
    """ContextVar ì„¤ì •ì„ ì´ì „ ìƒíƒœë¡œ ë³µì›"""
    try:
        crew_type_var.reset(token_ct)
        todo_id_var.reset(token_td)
        proc_id_var.reset(token_pid)
        form_id_var.reset(token_fid)
    except Exception as e:
        _handle_error("ì»¨í…ìŠ¤íŠ¸ë¦¬ì…‹", e)

# ============================================================================
# ìš”ì•½ ì²˜ë¦¬
# ============================================================================

def summarize(outputs: Any, feedbacks: Any, drafts: Any) -> str:
    """ì£¼ì–´ì§„ outputs, feedbacks, draftsë¥¼ LLMìœ¼ë¡œ ìš”ì•½"""
    try:
        print("\n\nìš”ì•½ì„ ìœ„í•œ LLMí˜¸ì¶œ ì‹œìž‘\n\n")
        
        # ë°ì´í„° ì¤€ë¹„
        outputs_str = _convert_to_string(outputs)
        feedbacks_str = _convert_to_string(feedbacks)
        drafts_str = _convert_to_string(drafts)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ
        prompt = _create_summary_prompt(outputs_str, feedbacks_str, drafts_str)
        summary = _call_openai_api(prompt)
        
        print(f"âœ… Context ìš”ì•½ ì™„ë£Œ: {len(summary)}ìž", flush=True)
        return summary
        
    except Exception as e:
        _handle_error("ìš”ì•½ì²˜ë¦¬", e)

def _convert_to_string(data: Any) -> str:
    """ë°ì´í„°ë¥¼ ë¬¸ìžì—´ë¡œ ë³€í™˜"""
    if isinstance(data, str):
        return data
    return json.dumps(data, ensure_ascii=False)

def _create_summary_prompt(outputs_str: str, feedbacks_str: str, drafts_str: str) -> str:
    """ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""ì´ì „ ìž‘ì—… ê²°ê³¼ë¬¼, ì¤‘ê°„ê²°ê³¼ë¬¼, í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.

**ë¶„ì„ ì›ì¹™:**
1. **êµ¬ì²´ì  ì •ë³´ ë³´ì¡´**: ìˆ˜ì¹˜, ëª©ì°¨ëª…, ì„¹ì…˜ëª…ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ì •í™•ížˆ ê¸°ë¡
2. **í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ**: ë¶ˆí•„ìš”í•œ í•´ì„ì´ë‚˜ ì¶”ê°€ ì§€ì‹œì‚¬í•­ ì—†ì´ ì‚¬ì‹¤ë§Œ ì •ë¦¬
3. **ê°€ë…ì„± ìš°ì„ **: ëª…í™•í•˜ê³  ê°„ê²°í•œ í˜•íƒœë¡œ êµ¬ì¡°í™”

**ìž…ë ¥ ë°ì´í„°:**
**ê²°ê³¼ë¬¼ ë‚´ìš©:** {outputs_str}
**ì¤‘ê°„ê²°ê³¼ë¬¼ ë‚´ìš©:** {drafts_str}
**í”¼ë“œë°± ë‚´ìš©:** {feedbacks_str}

**ìš”ì•½ í˜•ì‹:**

## ðŸ“Œ ê¸°ë³¸ ì •ë³´
- **ëª©ì **: [ê²°ê³¼ë¬¼ì„ ë³´ê³  ì´ì „ ìž‘ì—…ì˜ ëª©ì ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€]
- **ìš”êµ¬ì‚¬í•­**: [ê²°ê³¼ë¬¼ì„ ë³´ê³  ì–´ë–¤ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ë ¤ í–ˆëŠ”ì§€]

## ðŸ“‹ ì™„ë£Œëœ ê²°ê³¼ë¬¼
- **ì£¼ìš” ë‚´ìš©**: [ê²°ê³¼ë¬¼ì˜ í•µì‹¬ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ]
- **ëª©ì°¨/êµ¬ì¡°**: [ëª©ì°¨ë‚˜ ì„¹ì…˜ì´ ìžˆë‹¤ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë‚˜ì—´]
  - [ëª©ì°¨1]: [í•´ë‹¹ ì„¹ì…˜ í•µì‹¬ ë‚´ìš©]
  - [ëª©ì°¨2]: [í•´ë‹¹ ì„¹ì…˜ í•µì‹¬ ë‚´ìš©]
  - [ê³„ì†...]
- **ì£¼ìš” ìˆ˜ì¹˜/ë°ì´í„°**: [ì¤‘ìš”í•œ ìˆ«ìž, í†µê³„, ë°ì´í„°ê°€ ìžˆë‹¤ë©´]

## ðŸ”„ ì¤‘ê°„ê²°ê³¼ ë° í”¼ë“œë°± ì¢…í•© ë¶„ì„
- **ì² íšŒëœ ë‚´ìš©**: [ì¤‘ê°„ê²°ê³¼ë¬¼ì—ì„œ ë¬¸ì œê°€ ëœ ë¶€ë¶„]
- **ë¬¸ì œ ì›ì¸**: [ì™œ ì² íšŒë˜ì—ˆëŠ”ì§€, í”¼ë“œë°±ì—ì„œ ì§€ì ëœ ë¬¸ì œì ]
- **êµ¬ì²´ì  ê°œì„ ë°©í–¥**: [í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ì–´ë–»ê²Œ ê°œì„ í•´ì•¼ í•˜ëŠ”ì§€]
- **ì¶”ê°€ ìš”ì²­ì‚¬í•­**: [ìƒˆë¡œ ìš”ì²­ëœ ê¸°ëŠ¥ì´ë‚˜ ë‚´ìš©ì´ ìžˆë‹¤ë©´]

âš ï¸ **ì¤‘ìš”**: ëª¨ë“  ëª©ì°¨ëª…, ìˆ˜ì¹˜, ë°ì´í„°ëŠ” ì›ë³¸ê³¼ ì •í™•ížˆ ì¼ì¹˜í•˜ê²Œ ê¸°ë¡í•˜ê³ , í•´ì„ì´ë‚˜ ì¶”ê°€ ì œì•ˆ ì—†ì´ ì‚¬ì‹¤ë§Œ ì •ë¦¬í•˜ì„¸ìš”."""

def _get_system_prompt() -> str:
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
    return """ë‹¹ì‹ ì€ ì´ì „ ìž‘ì—… ê²°ê³¼ë¥¼ ì •í™•í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
- ì™„ë£Œëœ ê²°ê³¼ë¬¼ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì •í™•ížˆ ì¶”ì¶œ
- ì¤‘ê°„ê²°ê³¼ë¬¼ê³¼ í”¼ë“œë°±ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ê°œì„  ë°©í–¥ íŒŒì•…
- ëª©ì°¨, ìˆ˜ì¹˜, ë°ì´í„° ë“± êµ¬ì²´ì  ì •ë³´ë¥¼ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³´ì¡´
- ê°„ê²°í•˜ê³  ê°€ë…ì„± ë†’ì€ í˜•íƒœë¡œ í•µì‹¬ë§Œ ì •ë¦¬

ìž‘ì—… ì›ì¹™:
1. **ì •í™•ì„±**: ì›ë³¸ ì •ë³´ë¥¼ ì™œê³¡ ì—†ì´ ê·¸ëŒ€ë¡œ ê¸°ë¡
2. **ê°„ê²°ì„±**: ë¶ˆí•„ìš”í•œ í•´ì„ì´ë‚˜ ì¶”ê°€ ì œì•ˆ ì—†ì´ ì‚¬ì‹¤ë§Œ ì •ë¦¬
3. **êµ¬ì¡°í™”**: ëª©ì , ê²°ê³¼ë¬¼, ê°œì„ ë°©í–¥ìœ¼ë¡œ ì²´ê³„ì  ì •ë¦¬
4. **ì‹¤ìš©ì„±**: ë‹¤ìŒ ìž‘ì—…ì— í•„ìš”í•œ í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ë§Œ ì œê³µ
5. **ì¢…í•©ì„±**: ì¤‘ê°„ê²°ê³¼ì™€ í”¼ë“œë°±ì„ ì—°ê´€ì§€ì–´ í†µí•© ë¶„ì„"""

def _call_openai_api(prompt: str) -> str:
    """OpenAI API í˜¸ì¶œ"""
    response = openai.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": _get_system_prompt()},
            {"role": "user", "content": prompt}
        ],
        max_tokens=3000,
        temperature=0.1
    )
    return response.choices[0].message.content.strip()