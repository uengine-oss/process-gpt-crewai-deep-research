import asyncio
import logging
import json
import os
import sys
from typing import Optional, List, Dict, Any
from contextvars import ContextVar
from dotenv import load_dotenv

import psycopg2
from psycopg2.extras import RealDictCursor
from supabase import create_client, Client

# í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from .flows.multi_format_flow import MultiFormatFlow
from .feedback.diff_util import compare_report_changes, extract_changes
from .feedback.agent_feedback_analyzer import AgentFeedbackAnalyzer
from .context_manager import context_manager


# ============================================================================
# ê³µí†µ ì„¤ì • ë° ì´ˆê¸°í™”
# ============================================================================

logger = logging.getLogger("polling_manager")
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

# ê³µí†µ ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜
db_config_var = ContextVar('db_config', default={})
supabase_client_var = ContextVar('supabase', default=None)


def initialize_connections():
    """ë°ì´í„°ë² ì´ìŠ¤ ë° Supabase ì—°ê²° ì´ˆê¸°í™”"""
    try:
        if os.getenv("ENV") != "production":
            load_dotenv()

        # Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")
        supabase: Client = create_client(supabase_url, supabase_key)
        supabase_client_var.set(supabase)

        # PostgreSQL ì ‘ì† ì •ë³´ ì„¤ì •
        db_config = {
            "dbname": os.getenv("DB_NAME"),
            "user": os.getenv("DB_USER"),
            "password": os.getenv("DB_PASSWORD"),
            "host": os.getenv("DB_HOST"),
            "port": os.getenv("DB_PORT")
        }
        db_config_var.set(db_config)
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™” ì™„ë£Œ")

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {e}")


# ============================================================================
# ìƒˆ ì‘ì—… ì²˜ë¦¬ (TodoList Polling)
# ============================================================================

async def fetch_pending_tasks(limit: int = 1) -> Optional[List[Dict]]:
    """ìƒˆë¡œ ì²˜ë¦¬í•  ì‘ì—… ì¡°íšŒ (FOR UPDATE SKIP LOCKED)"""
    db_config = db_config_var.get()
    connection = psycopg2.connect(**db_config)
    connection.autocommit = False
    cursor = connection.cursor(cursor_factory=RealDictCursor)

    cursor.execute("""
        SELECT * FROM todolist
        WHERE agent_mode = 'DRAFT' 
        AND (draft IS NULL OR draft::text = '' OR draft::text = 'EMPTY') 
        AND status = 'IN_PROGRESS'
        ORDER BY start_date ASC LIMIT %s FOR UPDATE SKIP LOCKED
    """, (limit,))

    row = cursor.fetchone()
    if row:
        return [{'row': row, 'connection': connection, 'cursor': cursor}]
    else:
        cursor.close()
        connection.close()
        return None


async def _load_previous_outputs_to_context(proc_inst_id: Optional[str], activity_name: Optional[str]):
    """ê°™ì€ proc_inst_idì˜ ì™„ë£Œëœ ì‘ì—… outputì„ contextì— ì €ì¥"""
    if not proc_inst_id:
        return
    conn = None
    cursor = None
    try:
        db_config = db_config_var.get()
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute(
            """SELECT output FROM todolist
               WHERE proc_inst_id = %s AND status = 'DONE' AND output IS NOT NULL
               ORDER BY start_date ASC""",
            (proc_inst_id,)
        )
        rows = cursor.fetchall()
        outputs = [row['output'] if isinstance(row, dict) else row[0] for row in rows]
        if outputs:
            context_manager.save_context(proc_inst_id, activity_name or '', {'outputs': outputs})
            logger.info(f"ğŸ’¾ ì´ì „ ì™„ë£Œ ì‘ì—… outputs ì €ì¥: proc_inst_id={proc_inst_id}, activity_name={activity_name}, count={len(outputs)}")
    except Exception as e:
        logger.error(f"âŒ ì´ì „ ì™„ë£Œ ì‘ì—… outputs ë¡œë“œ ì˜¤ë¥˜ {proc_inst_id}: {e}")
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()


async def process_new_task(bundle: Dict):
    """ìƒˆ ì‘ì—… ì²˜ë¦¬ - ì»¨í…ì¸  ìƒì„±"""
    row, conn, cur = bundle['row'], bundle['connection'], bundle['cursor']

    try:
        logger.info(f"ğŸ†• ìƒˆ ì‘ì—… ì²˜ë¦¬: {row['id']}")
        
        # ì´ì „ ì™„ë£Œ ì‘ì—… outputs ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
        await _load_previous_outputs_to_context(
            row.get('proc_inst_id'),
            row.get('activity_name', '')
        )

        # ì‚¬ìš©ì ì •ë³´ ë° í¼ ì •ë³´ ì¡°íšŒ
        user_info = await _get_user_info(row.get('user_id'))
        form_types = await _get_form_types(row.get('tool', ''))
        
        # ì»¨í…ì¸  ìƒì„±
        result = await _generate_content(row, form_types, user_info)
        
        # ê²°ê³¼ ì €ì¥
        cur.execute("UPDATE todolist SET draft = %s WHERE id = %s", 
                   (json.dumps(result), row['id']))
        conn.commit()
        logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: {row['id']}")

    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ì²˜ë¦¬ ì˜¤ë¥˜ {row['id']}: {e}")
        cur.execute("UPDATE todolist SET draft = %s WHERE id = %s", (json.dumps({}), row['id']))
        conn.commit()
    finally:
        cur.close()
        conn.close()


async def _get_user_info(user_email: str) -> Dict:
    """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
    supabase = supabase_client_var.get()
    resp = supabase.table('users').select('username').eq('email', user_email).execute()
    username = resp.data[0]['username'] if resp.data else None
    
    return {
        'email': user_email,
        'name': username,
        'department': 'ì¸ì‚¬íŒ€',
        'position': 'ì‚¬ì›'
    }


async def _get_form_types(tool_val: str) -> List[Dict]:
    """í¼ íƒ€ì… ì •ë³´ ì¡°íšŒ ë° ì •ê·œí™”"""
    form_id = tool_val[12:] if tool_val.startswith('formHandler:') else tool_val
    
    supabase = supabase_client_var.get()
    resp = supabase.table('form_def').select('fields_json').eq('id', form_id).execute()
    fields_json = resp.data[0].get('fields_json') if resp.data else None
    
    if not fields_json:
        return [{'id': form_id, 'type': 'default'}]
    
    form_types = []
    for field in fields_json:
        field_type = field.get('type', '').lower()
        normalized_type = field_type if field_type in ['report', 'slide'] else 'text'
        form_types.append({
            'id': field.get('key'),
            'type': normalized_type,
            'key': field.get('key'),
            'text': field.get('text', '')
        })
    
    return form_types


async def _generate_content(row: Dict, form_types: List[Dict], user_info: Dict) -> Dict:
    """ì»¨í…ì¸  ìƒì„± ì‹¤í–‰"""
    # Flow ì‹¤í–‰
    flow = MultiFormatFlow()
    flow.state.topic = row.get('activity_name', '')
    flow.state.form_types = form_types
    flow.state.user_info = user_info
    flow.state.todo_id = row.get('id')
    flow.state.proc_inst_id = row.get('proc_inst_id')
    flow.state.form_id = form_types[0].get('id') if form_types else None
    
    result = await flow.kickoff_async()
    return result


# ============================================================================
# ì™„ë£Œ ì‘ì—… í”¼ë“œë°± ì²˜ë¦¬ (Feedback Polling)
# ============================================================================

async def fetch_completed_tasks(limit: int = 1) -> Optional[List[Dict]]:
    """í”¼ë“œë°± ëŒ€ìƒ ì™„ë£Œ ì‘ì—… ì¡°íšŒ"""
    db_config = db_config_var.get()
    connection = psycopg2.connect(**db_config)
    connection.autocommit = False
    cursor = connection.cursor(cursor_factory=RealDictCursor)

    try:
        cursor.execute("""
            UPDATE todolist SET feedback = '{}'::jsonb
            WHERE id = (
                SELECT id FROM todolist 
                WHERE status = 'DONE' AND output IS NOT NULL 
                AND draft IS NOT NULL 
                AND (feedback IS NULL OR feedback::text = '' OR feedback::text = 'EMPTY')
                ORDER BY start_date ASC LIMIT 1 FOR UPDATE SKIP LOCKED
            ) RETURNING *
        """)
        
        row = cursor.fetchone()
        if row:
            connection.commit()
            return [{'row': row, 'connection': connection, 'cursor': cursor}]
        else:
            cursor.close()
            connection.close()
            return None
            
    except Exception as e:
        logger.error(f"âŒ ì™„ë£Œ ì‘ì—… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        cursor.close()
        connection.close()
        return None


async def process_completed_task(bundle: Dict):
    """ì™„ë£Œ ì‘ì—… í”¼ë“œë°± ë¶„ì„"""
    row, conn, cur = bundle['row'], bundle['connection'], bundle['cursor']

    try:
        logger.info(f"ğŸ” í”¼ë“œë°± ë¶„ì„: {row['id']}")
        
        draft_value = row.get('draft')
        output_value = row.get('output')
        
        if not (draft_value and output_value):
            logger.warning(f"âš ï¸ draft ë˜ëŠ” output ì—†ìŒ: {row['id']}")
            return
        
        # ë³€ê²½ì‚¬í•­ ë¶„ì„
        feedback_list = await _analyze_changes(draft_value, output_value, row)
        
        # í”¼ë“œë°± ì €ì¥
        cur.execute("UPDATE todolist SET feedback = %s WHERE id = %s",
                   (json.dumps(feedback_list, ensure_ascii=False), row['id']))
        conn.commit()
        
        logger.info(f"âœ… í”¼ë“œë°± ì €ì¥ ì™„ë£Œ: {row['id']} ({len(feedback_list)}ê°œ)")

    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜ {row['id']}: {e}")
        conn.rollback()
    finally:
        cur.close()
        conn.close()


async def _analyze_changes(draft_value: Any, output_value: Any, row: Dict) -> List[Dict]:
    """ë³€ê²½ì‚¬í•­ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±"""
    try:
        # Diff ë¶„ì„
        diff_result = compare_report_changes(
            json.dumps(draft_value) if isinstance(draft_value, dict) else str(draft_value),
            json.dumps(output_value) if isinstance(output_value, dict) else str(output_value)
        )
        
        if not diff_result.get('unified_diff'):
            logger.info("ğŸ“ ë³€ê²½ì‚¬í•­ ì—†ìŒ")
            return []
        
        # ë³€ê²½ì‚¬í•­ ë¡œê¹…
        extract_changes(
            diff_result.get('draft_content', ''), 
            diff_result.get('output_content', '')
        )

        # ì—ì´ì „íŠ¸ í”¼ë“œë°± ìƒì„±
        analyzer = AgentFeedbackAnalyzer()
        
        feedback_list = await analyzer.analyze_diff_and_generate_feedback(
            json.dumps(draft_value) if isinstance(draft_value, dict) else str(draft_value),
            json.dumps(output_value) if isinstance(output_value, dict) else str(output_value),
            todo_id=row.get('id'),
            proc_inst_id=row.get('proc_inst_id')
        )
        
        return feedback_list or []
        
    except Exception as e:
        logger.error(f"âŒ ë³€ê²½ì‚¬í•­ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return []


# ============================================================================
# í†µí•© Polling ì‹¤í–‰ë¶€
# ============================================================================

async def start_todolist_polling(interval: int = 7):
    """ìƒˆ ì‘ì—… ì²˜ë¦¬ í´ë§ ì‹œì‘"""
    logger.info("ğŸš€ TodoList í´ë§ ì‹œì‘")
    while True:
        try:
            tasks = await fetch_pending_tasks()
            if tasks:
                for bundle in tasks:
                    await process_new_task(bundle)
        except Exception as e:
            logger.error(f"âŒ TodoList í´ë§ ì˜¤ë¥˜: {e}")
        await asyncio.sleep(interval)


async def start_feedback_polling(interval: int = 10):
    """ì™„ë£Œ ì‘ì—… í”¼ë“œë°± í´ë§ ì‹œì‘"""
    logger.info("ğŸš€ í”¼ë“œë°± í´ë§ ì‹œì‘")
    while True:
        try:
            tasks = await fetch_completed_tasks()
            if tasks:
                for bundle in tasks:
                    await process_completed_task(bundle)
        except Exception as e:
            logger.error(f"âŒ í”¼ë“œë°± í´ë§ ì˜¤ë¥˜: {e}")
        await asyncio.sleep(interval)